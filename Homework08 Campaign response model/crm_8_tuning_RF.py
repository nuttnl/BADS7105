# -*- coding: utf-8 -*-
"""CRM 8 tuning nut

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gHvmPgyfKOmtVA4iPzJY-nO2i4uN6a7j
"""

import numpy as np
import pandas as pd
import datetime as dt
import numpy as np
import matplotlib.pyplot as plt
import xgboost as xgb
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report, roc_curve, auc
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from imblearn.over_sampling import SMOTE
from xgboost import plot_importance
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix

df_response = pd.read_csv('/content/drive/MyDrive/CRM/Retail_Data_Response.csv')
df_transactions = pd.read_csv('/content/drive/MyDrive/CRM/Retail_Data_Transactions.csv', parse_dates=['trans_date'])

df_response.head()

df_transactions.head()

print(df_transactions['trans_date'].min())
print(df_transactions['trans_date'].max())

campaign_date = dt.datetime(2015,3,17)
df_transactions['recent']= campaign_date - df_transactions['trans_date']
df_transactions['recent'].astype('timedelta64[D]')
df_transactions['recent']=df_transactions['recent'] / np.timedelta64(1, 'D')
df_transactions.head()



## create data set with RFM variables

df_rfm = df_transactions.groupby('customer_id').agg({'recent': lambda x:x.min(),                      # Recency
                                                     'customer_id': lambda x: len(x),                 # Frequency
                                                     'tran_amount': lambda x: x.sum()})               # Monetary Value           


df_rfm.rename(columns={'recent': 'recency', 
                       'customer_id': 'frequency', 
                       'tran_amount': 'monetary_value'}, inplace=True)
#df_rfm['ticket_size'] = df_rfm['monetary_value'] / df_rfm['frequency']

df_rfm = df_rfm.reset_index()
df_rfm.head()
print(df_rfm['monetary_value'].min())
print(df_rfm['monetary_value'].max())
#print(df_rfm['frequency'].min())
#print(df_rfm['frequency'].max())
#print(df_rfm['recency'].min())
#print(df_rfm['recency'].max())

#col = df_rfm.drop['customer_id']
#col.head()

from sklearn.preprocessing import MinMaxScaler

# Scale only columns that have values greater than 1
#to_scale = [col for col in df_rfm.columns if df_rfm[col].max() > 1 else ]
mms = MinMaxScaler()

df_rfm[['monetary_value']] = mms.fit_transform(df_rfm[['monetary_value']])
    
df_rfm.head()

df_rfm.info()
df_rfm.head()

## create data set with CLV variables

df_clv = df_transactions.groupby('customer_id').agg({'recent': lambda x:x.min(),                      # Recency
                                                     'customer_id': lambda x: len(x),                 # Frequency
                                                     'tran_amount': lambda x: x.sum(),                # Monetary Value           
                                                     'trans_date': lambda x: (x.max() - x.min()).days})       # AOU

df_clv.rename(columns={'recent': 'recency', 
                       'customer_id': 'frequency', 
                       'tran_amount': 'monetary_value',
                       'trans_date' : 'AOU'}, inplace=True)

df_clv['ticket_size'] = df_clv['monetary_value'] / df_clv['frequency']

df_clv = df_clv.reset_index()
df_clv.head()

from sklearn.preprocessing import MinMaxScaler

# Scale only columns that have values greater than 1
#to_scale = [col for col in df_rfm.columns if df_rfm[col].max() > 1 else ]
mms = MinMaxScaler()

df_clv[['monetary_value']] = mms.fit_transform(df_clv[['monetary_value']])
    
df_clv.head()

#prove Y - response is imbalance or not

response_rate = df_response.groupby('response').agg({'customer_id': lambda x: len(x)}).reset_index()
response_rate.head()

plt.figure(figsize=(5,5))
x=range(2)
plt.bar(x,response_rate['customer_id'])
plt.xticks(response_rate.index)
plt.title('Response Distribution')
plt.xlabel('Convert or Not')
plt.ylabel('no. of users')
plt.show()

## data is imbalanced



## merging two data sets - RFM

df_modeling_rfm = pd.merge(df_response,df_rfm)
df_modeling_rfm.head()

## merging two data sets - CLV

df_modeling_clv = pd.merge(df_response,df_clv)
df_modeling_clv.head()

## spliting dataframe into X and y
#RFM
X_rfm = df_modeling_rfm.drop(columns=['response','customer_id'])
y_rfm = df_modeling_rfm['response']

#CLV
X_clv = df_modeling_clv.drop(columns=['response','customer_id'])
y_clv = df_modeling_clv['response']

## creating train and test dataset
#RFM
X_train_rfm, X_test_rfm, y_train_rfm, y_test_rfm = train_test_split(X_rfm, y_rfm, test_size=0.3, random_state=0)
#CLV
X_train_clv, X_test_clv, y_train_clv, y_test_clv = train_test_split(X_clv, y_clv, test_size=0.3, random_state=0)

# create dummy variable because data is imbalanced
sm = SMOTE(random_state=0)
#RFM
sm.fit(X_train_rfm, y_train_rfm)
X_SMOTE_rfm, y_SMOTE_rfm = sm.fit_sample(X_train_rfm, y_train_rfm)

#CLV
sm.fit(X_train_clv, y_train_clv)
X_SMOTE_clv, y_SMOTE_clv = sm.fit_sample(X_train_clv, y_train_clv)

print('logistic regression model - SMOTE RFM')
logreg = LogisticRegression(solver='liblinear', class_weight='balanced')
predicted_y = []
expected_y = []

logreg_model_SMOTE_rfm = logreg.fit(X_SMOTE_rfm, y_SMOTE_rfm)
predictions = logreg_model_SMOTE_rfm.predict(X_SMOTE_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_rfm)
report_train = classification_report(expected_y, predicted_y)
print('training set')
print(report_train) 

predicted_y = []
expected_y = []
predictions = logreg_model_SMOTE_rfm.predict(X_test_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_test_rfm)
report_test = classification_report(expected_y, predicted_y)
print('test set')
print(report_test)

print('Random Forest Model - SMOTE CLV')
#Import Random Forest Model
from sklearn.ensemble import RandomForestClassifier

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)


predicted_y = []
expected_y = []

rend_model_SMOTE_rfm =  clf.fit(X_SMOTE_rfm, y_SMOTE_rfm)
predictions =rend_model_SMOTE_rfm.predict(X_SMOTE_rfm)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_rfm)
print(predicted_y)
report_train = classification_report(expected_y, predicted_y)
print('training set')
print(report_train) 

predicted_y_test = []
expected_y_test = []
predictions = rend_model_SMOTE_rfm.predict(X_test_rfm)
predicted_y_test.extend(predictions)
expected_y_test.extend(y_test_rfm)
report_test = classification_report(expected_y_test, predicted_y_test)
print('test set')
print(report_test)

print('Random Forest Model - SMOTE CLV')
#Import Random Forest Model
from sklearn.ensemble import RandomForestClassifier

#Create a Gaussian Classifier
clf=RandomForestClassifier(n_estimators=100)

#Train the model using the training sets y_pred=clf.predict(X_test)


predicted_y = []
expected_y = []

rend_model_SMOTE_clv =  clf.fit(X_SMOTE_clv, y_SMOTE_clv)
predictions =rend_model_SMOTE_clv.predict(X_SMOTE_clv)
predicted_y.extend(predictions)
expected_y.extend(y_SMOTE_clv)
print(predicted_y)
report_train = classification_report(expected_y, predicted_y)
print('training set')
print(report_train) 

predicted_y_test = []
expected_y_test = []
predictions = rend_model_SMOTE_clv.predict(X_test_clv)
predicted_y_test.extend(predictions)
expected_y_test.extend(y_test_clv)
report_test = classification_report(expected_y_test, predicted_y_test)
#print('test set')
print(report_test)

